{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the spectrogram image dataset from raw audio file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script was used to generate the spectrogram image dataset, from the .wav raw audio files, that was used to train the CNN classifier. It is for informative purposes only and **doesn't need to be run again to classify an image using our classifier.** However, if you wish to use the functions in this script, simply modify the hardcoded filepaths in the \"Hardcoded Filepaths\" chunk to fit your machine's architecture.\n",
    "\n",
    "**Note: The raw audio .wav files must already be split in train/validation/test format on the drive/machine for this script to function as intended.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-18e4683141a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/skimage/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_shared\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardcoded filepaths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels dataframe from the manually labelled training examples in the .csv file\n",
    "labs = pd.read_csv('/mntDrive/My Drive/VoxCeleb_theo/label.csv')\n",
    "\n",
    "# Get filepaths of each .wav file for each ID that are already split in train/validation/test format in the drive\n",
    "train = glob.glob(str('/mntDrive/My Drive/VoxCeleb_theo/train/*/*.wav'))\n",
    "val = glob.glob(str('/mntDrive/My Drive/VoxCeleb_theo/val/*/*.wav'))\n",
    "test = glob.glob(str('/mntDrive/My Drive/VoxCeleb_theo/test/*/*.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through training, validation, and testing datasets of .wav raw audio files\n",
    "for step in [train, val, test]:\n",
    "    # Iterate over the ids directory found in each training, validation, and testing datasets\n",
    "    for idx in step:\n",
    "        # Extract waveform and sample rate from each .wav file\n",
    "        waveform, sample_rate = torchaudio.load(idx)\n",
    "        # Select only the first 6 seconds of each audio file for consistency\n",
    "        waveform = waveform[:,:60000]\n",
    "        # Apply Mel Spectrogram transformation on amplitude over time file (generates a tensor)\n",
    "        specgram = torchaudio.transforms.MelSpectrogram()(waveform)\n",
    "        # Transform the spectrogram into log2 base and transform as numpy array for exportation as image\n",
    "        specgram = specgram.log2()[0,:,:].detach().numpy()\n",
    "        # Convert the pixel scale for exportation in matplotlib\n",
    "        specgram = cv2.convertScaleAbs(specgram, alpha=(1))\n",
    "        # Extract the label (1 or 0) for each sample to assign to the right filepath\n",
    "        l = labs[labs.id == int(idx.split('/')[-2][2:])].label.values[0]\n",
    "        # Generate the destination filepath for the transformed spectrogram image\n",
    "        new_path = str('/mntDrive/My Drive/VoxCeleb_theo/images/'+idx.split('/')[-3]+'/'+str(l) +'/'+idx.split('/')[-2]+'_'+idx.split('/')[-1][:-4]+'.jpg')\n",
    "        # For verification purposes\n",
    "        print(new_path)    \n",
    "        # Save the image to the filepath above in grayscale as image channel brings no classifying information\n",
    "        plt.imsave(new_path,specgram,cmap='gray')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
